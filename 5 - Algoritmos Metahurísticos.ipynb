{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGe7It63WTrlhNbyg14pPS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Resumen del problema\n","\n","Seleccionar un subconjunto de variables que maximice el rendimiento de un clasificador (por ejemplo, un árbol de decisión), usando un dataset real y evaluando la precisión de clasificación como medida de aptitud (fitness).\n","\n","Algoritmos metaheurísticos :\n","\n","1. Recocido simulado (Simulated Annealing - SA)\n","2. Algoritmo genético (Genetic Algorithm - GA)"],"metadata":{"id":"cycrRbLJS2LU"}},{"cell_type":"markdown","source":["### Dataset base para pruebas\n","\n","Usaremos el dataset breast_cancer de sklearn.datasets (es pequeño, multivariable y típico para evaluación de selección de características)."],"metadata":{"id":"tgDl5NKASs-G"}},{"cell_type":"markdown","source":["### Configuración general antes de los algoritmos"],"metadata":{"id":"52ve2iKVT6aE"}},{"cell_type":"markdown","source":["### Importar librerías"],"metadata":{"id":"LzgNdY8RT_Sh"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.datasets import load_breast_cancer\n","# Carga un conjunto de datos real de cáncer de mama incluido en scikit-learn.\n","# Este dataset contiene 30 características (variables) que se usarán como base\n","# para aplicar selección de variables con metaheurísticas.\n","\n","from sklearn.model_selection import cross_val_score\n","# Permite evaluar el rendimiento de un modelo con validación cruzada.\n","# Se usa para medir qué tan buena es una solución (subconjunto de variables),\n","# calculando la precisión promedio en varias particiones de los datos.\n","\n","from sklearn.tree import DecisionTreeClassifier\n","# Clasificador basado en árboles de decisión.\n","# En este caso, lo usamos como modelo base para evaluar la calidad\n","# de los subconjuntos de variables seleccionados por los algoritmos."],"metadata":{"id":"voUTvseDT-o3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cargar datos reales"],"metadata":{"id":"2BIL7-tqwAmR"}},{"cell_type":"code","source":["data = load_breast_cancer()\n","# Carga el dataset de cáncer de mama desde sklearn.\n","# Este conjunto de datos incluye características de imágenes digitales de células\n","# y una etiqueta binaria (maligno o benigno) como variable objetivo.\n","\n","X = data.data\n","# Extrae las variables predictoras (matriz de características).\n","# Cada fila representa un paciente y cada columna una característica (por ejemplo, textura, área, simetría).\n","\n","y = data.target\n","# Extrae la variable objetivo (etiquetas: 0 = maligno, 1 = benigno).\n","\n","n_features = X.shape[1]\n","# Calcula el número total de características (columnas) disponibles en X.\n","# Esto es útil para saber cuántas variables se pueden seleccionar durante la optimización."],"metadata":{"id":"rEJXtz9vwEHv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Convertir a DataFrame para visualizar el conjunto de datos"],"metadata":{"id":"M-iL1PgyYQRd"}},{"cell_type":"code","source":["df = pd.DataFrame(data.data, columns=data.feature_names)\n","\n","# Agregar la columna de etiquetas (diagnóstico: maligno o benigno)\n","df['target'] = data.target\n","\n","# Mostrar las primeras 5 filas\n","df.head()"],"metadata":{"id":"DXygDEmmX_nw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dimensiones del dataset"],"metadata":{"id":"7gkNrGbdYvEa"}},{"cell_type":"code","source":["print(df.shape)\n","print('Cantidad de registros:', df.shape[0])\n","print('Cantidad de variables:', df.shape[1])"],"metadata":{"id":"GmMZgUZxYvNS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables o característas del dataset"],"metadata":{"id":"kw45YUYnYkb4"}},{"cell_type":"code","source":["print(data.feature_names)"],"metadata":{"id":"fqSwQPzvYOX4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Información del dataset"],"metadata":{"id":"aRFfmA9tZPQK"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"MJgPg9T_ZK4t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Estadísticas del dataset"],"metadata":{"id":"qfYa9n1VZS-6"}},{"cell_type":"code","source":["df.describe(include='all')"],"metadata":{"id":"fwlix4QkZSZs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Función de evaluación (fitness): precisión media con validación cruzada\n","\n","Esta función es el corazón del problema de optimización: las metaheurísticas (como recocido simulado o algoritmo genético) generan soluciones candidatas (máscaras binarias) y esta función les dice qué tan buena es cada una, basándose en la precisión de clasificación.\n","\n"],"metadata":{"id":"UbFm8MOPwHKE"}},{"cell_type":"code","source":["def evaluate_solution(mask):\n","    # Esta función evalúa qué tan buena es una solución (máscara de selección de variables)\n","    # La entrada 'mask' es un vector binario del mismo tamaño que el número de características (features).\n","    # Por ejemplo, si mask = [1, 0, 1, 0], significa que solo se están usando las variables 0 y 2.\n","\n","    if np.sum(mask) == 0:\n","        # Si no se selecciona ninguna variable (todos los valores en mask son 0),\n","        # no se puede entrenar un modelo. En ese caso, se devuelve precisión = 0.\n","        return 0\n","\n","    # Selecciona solo las columnas de X donde mask == 1 (es decir, las variables activadas)\n","    X_selected = X[:, mask == 1]\n","\n","    # Se elige un modelo de árbol de decisión como clasificador base\n","    clf = DecisionTreeClassifier()\n","\n","    # Se evalúa la precisión promedio usando validación cruzada de 5 pliegues (5-fold cross-validation)\n","    # Esto ayuda a estimar qué tan bien generaliza la selección de variables sin sobreajuste\n","    score = cross_val_score(clf, X_selected, y, cv=5).mean()\n","\n","    # Se retorna la precisión media como la medida de calidad (fitness) de la solución\n","    return score"],"metadata":{"id":"Z62478_jwHU5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Recocido Simulado (Simulated Annealing)\n","\n","Este algoritmo imita el proceso físico de enfriamiento de metales, permitiendo al sistema \"explorar\" soluciones peores al principio (para evitar quedarse atrapado en mínimos locales), y luego refinar progresivamente la búsqueda hasta encontrar una solución óptima o cercana.\n","\n"],"metadata":{"id":"tAC2J_pZwUrQ"}},{"cell_type":"code","source":["# Biblioteca estándar usada para selección aleatoria de elementos\n","import random\n","\n","# Recocido simulado para selección de variables\n","def simulated_annealing(n_iterations=1000, initial_temp=1.0, cooling_rate=0.995):\n","    \"\"\"\n","    Implementa el algoritmo de Recocido Simulado (Simulated Annealing) para seleccionar\n","    un subconjunto de variables que maximice la precisión de un clasificador.\n","\n","    Parámetros:\n","    - n_iterations: número total de iteraciones a ejecutar.\n","    - initial_temp: temperatura inicial del sistema (controla la probabilidad de aceptar soluciones peores al inicio).\n","    - cooling_rate: factor por el cual se reduce la temperatura en cada iteración (debe estar entre 0 y 1).\n","\n","    Retorna:\n","    - best: la mejor máscara binaria encontrada (variables seleccionadas).\n","    - best_score: precisión promedio (fitness) de esa mejor solución.\n","    \"\"\"\n","\n","    # Generar solución inicial aleatoria: vector binario (0 o 1) del mismo tamaño que el número de características\n","    current = np.random.randint(0, 2, size=n_features)\n","\n","    # Evaluar la calidad (precisión) de la solución inicial\n","    current_score = evaluate_solution(current)\n","\n","    # Guardar la mejor solución conocida hasta el momento (inicialmente es la misma)\n","    best = current.copy()\n","    best_score = current_score\n","\n","    # Establecer temperatura inicial\n","    temp = initial_temp\n","\n","    # Ciclo principal del algoritmo (iteraciones)\n","    for i in range(n_iterations):\n","\n","        # Crear una solución vecina modificando una sola variable aleatoriamente\n","        neighbor = current.copy()\n","        idx = np.random.randint(n_features)  # escoger una posición aleatoria\n","        neighbor[idx] = 1 - neighbor[idx]    # cambiar de 0→1 o de 1→0\n","\n","        # Evaluar la nueva solución vecina\n","        neighbor_score = evaluate_solution(neighbor)\n","\n","        # Calcular la diferencia en rendimiento (delta)\n","        delta = neighbor_score - current_score\n","\n","        # Criterio de aceptación tipo Metropolis:\n","        # - Si la nueva solución es mejor (delta > 0), se acepta siempre.\n","        # - Si es peor, se acepta con cierta probabilidad que depende de delta y la temperatura.\n","        if delta > 0 or np.exp(delta / temp) > np.random.rand():\n","            current = neighbor\n","            current_score = neighbor_score\n","\n","            # Si además esta nueva solución es la mejor de todas, la guardamos\n","            if current_score > best_score:\n","                best = current.copy()\n","                best_score = current_score\n","\n","        # Reducir la temperatura gradualmente (enfriamiento simulado)\n","        temp *= cooling_rate\n","\n","        # Mostrar información de progreso cada 50 iteraciones y en la última\n","        if i % 50 == 0 or i == n_iterations - 1:\n","            print(f\"Iteración {i}: Precisión = {current_score:.4f}, Temp = {temp:.4f}\")\n","\n","    # Al finalizar, se retorna la mejor solución encontrada\n","    return best, best_score"],"metadata":{"id":"CwcPCvvxwU2e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Algoritmo Genético (Genetic Algorithm)\n","\n","¿Qué hace este algoritmo?\n","* Crea una población inicial de soluciones (máscaras binarias de selección de variables).\n","* Evalúa su desempeño mediante validación cruzada.\n","* Selecciona los mejores individuos para formar la siguiente generación.\n","* Genera nuevos individuos aplicando cruce y mutación.\n","* Itera por varias generaciones, refinando las soluciones.\n","* Devuelve el mejor conjunto de variables al final del proceso.\n","\n"],"metadata":{"id":"a_L4r785lFo9"}},{"cell_type":"code","source":["def genetic_algorithm(pop_size=20, generations=50, crossover_rate=0.8, mutation_rate=0.1):\n","    \"\"\"\n","    Algoritmo genético para seleccionar un subconjunto óptimo de variables que maximice\n","    el rendimiento de un clasificador (en este caso, un árbol de decisión).\n","\n","    Parámetros:\n","    - pop_size: número de individuos en la población.\n","    - generations: número total de generaciones que se van a evolucionar.\n","    - crossover_rate: probabilidad de realizar cruce entre padres.\n","    - mutation_rate: probabilidad de mutar un hijo.\n","\n","    Retorna:\n","    - best_ind: el mejor individuo (máscara de variables seleccionadas).\n","    - score: precisión (fitness) de ese individuo.\n","    \"\"\"\n","\n","    # Paso 1: Inicializar la población con soluciones aleatorias (vectores binarios)\n","    population = [np.random.randint(0, 2, size=n_features) for _ in range(pop_size)]\n","\n","    # Paso 2: Iterar por cada generación (ciclo evolutivo)\n","    for gen in range(generations):\n","\n","        # Evaluar el desempeño (aptitud) de cada individuo de la población\n","        scores = [evaluate_solution(ind) for ind in population]\n","\n","        # Selección: se escogen los mejores individuos para reproducirse (ordenados por puntaje)\n","        # np.argsort(scores)[-pop_size:] obtiene los índices de los mejores individuos\n","        selected = [population[i] for i in np.argsort(scores)[-pop_size:]]\n","\n","        # Inicializar nueva población\n","        new_population = []\n","\n","        # Paso 3: Generar nuevos individuos (hijos) hasta llenar la nueva población\n","        while len(new_population) < pop_size:\n","            # Selección aleatoria de dos padres entre los mejores\n","            parents = random.sample(selected, 2)\n","\n","            # Cruce (recombinación genética) con cierta probabilidad\n","            if np.random.rand() < crossover_rate:\n","                # Seleccionar un punto de corte aleatorio\n","                point = np.random.randint(1, n_features - 1)\n","                # Crear dos hijos combinando partes de los padres\n","                child1 = np.concatenate((parents[0][:point], parents[1][point:]))\n","                child2 = np.concatenate((parents[1][:point], parents[0][point:]))\n","            else:\n","                # Si no hay cruce, los hijos son copias directas de los padres\n","                child1, child2 = parents\n","\n","            # Mutación: cada hijo puede tener una variable invertida aleatoriamente\n","            for child in [child1, child2]:\n","                if np.random.rand() < mutation_rate:\n","                    idx = np.random.randint(n_features)\n","                    child[idx] = 1 - child[idx]  # invierte el bit (0 → 1 o 1 → 0)\n","\n","                # Agregar el hijo a la nueva población\n","                new_population.append(child)\n","\n","        # Reemplazar la población vieja por la nueva\n","        population = new_population[:pop_size]  # asegurar que no exceda el tamaño\n","\n","        # Reporte de progreso: imprimir mejor puntuación de esta generación\n","        best_idx = np.argmax([evaluate_solution(ind) for ind in population])\n","        print(f\"Generación {gen + 1}: Mejor precisión = {evaluate_solution(population[best_idx]):.4f}\")\n","\n","    # Paso 4: Después de todas las generaciones, retornar el mejor individuo encontrado\n","    best_ind = max(population, key=evaluate_solution)\n","    return best_ind, evaluate_solution(best_ind)"],"metadata":{"id":"hU8wNrjTu07x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Comparación final"],"metadata":{"id":"1PRHM7esu0Ca"}},{"cell_type":"code","source":["# Ejecutar recocido simulado\n","print(\"== Recocido simulado ==\")\n","best_sa, score_sa = simulated_annealing()\n","print(f\"Mejor precisión SA: {score_sa:.4f}\")\n","print(f\"Variables seleccionadas: {np.sum(best_sa)}\")\n","\n","# Mostrar nombres de las variables seleccionadas\n","selected_features_sa = data.feature_names[best_sa == 1]\n","print(\"Características seleccionadas (SA):\")\n","for feature in selected_features_sa:\n","    print(f\"- {feature}\")\n","\n","# ========================================================\n","\n","# Ejecutar algoritmo genético\n","print(\"\\n== Algoritmo genético ==\")\n","best_ga, score_ga = genetic_algorithm()\n","print(f\"Mejor precisión GA: {score_ga:.4f}\")\n","print(f\"Variables seleccionadas: {np.sum(best_ga)}\")\n","\n","# Mostrar nombres de las variables seleccionadas\n","selected_features_ga = data.feature_names[best_ga == 1]\n","print(\"Características seleccionadas (GA):\")\n","for feature in selected_features_sa:\n","    print(f\"- {feature}\")"],"metadata":{"id":"zageuMVZnOvM"},"execution_count":null,"outputs":[]}]}