{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFmJmRmnR46iA+8pUsrtMT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Resumen del problema\n","\n","Seleccionar un subconjunto de variables que maximice el rendimiento de un algoritmo de ensamble para regresión (por ejemplo, bosques aleatorios), usando un dataset real y evaluando R² (coeficiente de determinación) como medida de aptitud (fitness).\n","\n","Algoritmos metaheurísticos :\n","\n","1. Recocido simulado (Simulated Annealing - SA)\n","2. Algoritmo genético (Genetic Algorithm - GA)\n","3. Enjambre de partículas (Particle Swarm Optimization, PSO)"],"metadata":{"id":"cycrRbLJS2LU"}},{"cell_type":"markdown","source":["### Dataset base para pruebas\n","\n","Usaremos el dataset diabetes de sklearn.datasets."],"metadata":{"id":"tgDl5NKASs-G"}},{"cell_type":"markdown","source":["### Configuración general antes de los algoritmos"],"metadata":{"id":"52ve2iKVT6aE"}},{"cell_type":"markdown","source":["### Importar librerías"],"metadata":{"id":"LzgNdY8RT_Sh"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# Utilizada para selección aleatoria de elementos\n","import random\n","\n","from sklearn.datasets import load_diabetes\n","# Carga un conjunto de datos real de diabetes incluido en scikit-learn.\n","# Este dataset contiene 10 características (variables) que se usarán como base\n","# para aplicar selección de variables con metaheurísticas.\n","\n","from sklearn.model_selection import cross_val_score\n","# Permite evaluar el rendimiento de un modelo con validación cruzada.\n","# Se usa para medir qué tan buena es una solución (subconjunto de variables),\n","# calculando la precisión promedio en varias particiones de los datos.\n","\n","from sklearn.metrics import make_scorer, mean_squared_error\n","# make_scorer para crear métricas personalizadas compatibles con scikit-learn y\n","# mean_squared_error para calcular el error cuadrático medio (MSE)\n","\n","from sklearn.ensemble import RandomForestRegressor\n","# Algoritmo de regresión RandomForest.\n","# En este caso, lo usamos como modelo base para evaluar la calidad\n","# de los subconjuntos de variables seleccionados por los algoritmos."],"metadata":{"id":"voUTvseDT-o3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cargar datos reales"],"metadata":{"id":"2BIL7-tqwAmR"}},{"cell_type":"code","source":["data = load_diabetes()\n","X = data.data\n","y = data.target\n","\n","n_features = X.shape[1]"],"metadata":{"id":"rEJXtz9vwEHv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Convertir a DataFrame para visualizar el conjunto de datos"],"metadata":{"id":"M-iL1PgyYQRd"}},{"cell_type":"code","source":["df = pd.DataFrame(data.data, columns=data.feature_names)\n","df['target'] = data.target\n","df.head()"],"metadata":{"id":"DXygDEmmX_nw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dimensiones del dataset"],"metadata":{"id":"7gkNrGbdYvEa"}},{"cell_type":"code","source":["print(df.shape)\n","print('Cantidad de registros:', df.shape[0])\n","print('Cantidad de variables:', df.shape[1])"],"metadata":{"id":"GmMZgUZxYvNS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables o característas del dataset"],"metadata":{"id":"kw45YUYnYkb4"}},{"cell_type":"code","source":["print(data.feature_names)"],"metadata":{"id":"fqSwQPzvYOX4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Información del dataset"],"metadata":{"id":"aRFfmA9tZPQK"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"MJgPg9T_ZK4t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Función de evaluación (fitness): precisión media con validación cruzada\n","\n","Esta función es el corazón del problema de optimización: las metaheurísticas (como recocido simulado o algoritmo genético) generan soluciones candidatas (máscaras binarias) y esta función les dice qué tan buena es cada una, basándose en la precisión de clasificación.\n","\n"],"metadata":{"id":"UbFm8MOPwHKE"}},{"cell_type":"code","source":["def evaluate_solution(mask):\n","    # Esta función evalúa qué tan buena es una solución (máscara de selección de variables)\n","    # La entrada 'mask' es un vector binario del mismo tamaño que el número de características (features).\n","    # Por ejemplo, si mask = [1, 0, 1, 0], significa que solo se están usando las variables 0 y 2.\n","\n","    if np.sum(mask) == 0:\n","        # Si no se selecciona ninguna variable (todos los valores en mask son 0),\n","        # no se puede entrenar un modelo. En ese caso, se devuelve precisión = 0.\n","        return 0\n","\n","    # Selecciona solo las columnas de X donde mask == 1 (es decir, las variables activadas)\n","    X_selected = X[:, mask == 1]\n","\n","    # Se elige un modelo RandomForest para regresión con 25 estimadores\n","    regr = RandomForestRegressor(n_estimators=2, random_state=42)\n","\n","    # Se evalúa la precisión (R2) promedio usando validación cruzada de 5 pliegues (5-fold cross-validation)\n","    # Esto ayuda a estimar qué tan bien generaliza la selección de variables sin sobreajuste\n","    score = cross_val_score(regr, X_selected, y, cv=5).mean()\n","\n","    # Si se desea cambiar la métrica a RMSE, se tendrá que hacer explícitamente:\n","    # score = cross_val_score(regr, X_selected, y, scoring='neg_root_mean_squared_error', cv=5).mean()\n","    # scoring='neg_root_mean_squared_error' devuelve RMSE negativo a propósito, porque sigue la\n","    # convención de que métricas de error deben ser maximizadas si se invierte el signo.\n","\n","    # Se retorna la precisión media como la medida de calidad (fitness) de la solución\n","    return score"],"metadata":{"id":"Z62478_jwHU5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Recocido Simulado (Simulated Annealing, SA)\n","\n","Este algoritmo imita el proceso físico de enfriamiento de metales, permitiendo al sistema \"explorar\" soluciones peores al principio (para evitar quedarse atrapado en mínimos locales), y luego refinar progresivamente la búsqueda hasta encontrar una solución óptima o cercana.\n","\n"],"metadata":{"id":"tAC2J_pZwUrQ"}},{"cell_type":"code","source":["def simulated_annealing(n_iterations=100, initial_temp=1.0, cooling_rate=0.995):\n","    \"\"\"\n","    Implementa el algoritmo de Recocido Simulado (Simulated Annealing) para seleccionar\n","    un subconjunto de variables que maximice la precisión de un estimador.\n","\n","    Parámetros:\n","    - n_iterations: número total de iteraciones a ejecutar.\n","    - initial_temp: temperatura inicial del sistema (controla la probabilidad de aceptar soluciones peores al inicio).\n","    - cooling_rate: factor por el cual se reduce la temperatura en cada iteración (debe estar entre 0 y 1).\n","\n","    Retorna:\n","    - best: la mejor máscara binaria encontrada (variables seleccionadas).\n","    - best_score: precisión promedio (fitness) de esa mejor solución.\n","    \"\"\"\n","\n","    # Generar solución inicial aleatoria: vector binario (0 o 1) del mismo tamaño que el número de características\n","    current = np.random.randint(0, 2, size=n_features)\n","\n","    # Evaluar la calidad (precisión) de la solución inicial\n","    current_score = evaluate_solution(current)\n","\n","    # Guardar la mejor solución conocida hasta el momento (inicialmente es la misma)\n","    best = current.copy()\n","    best_score = current_score\n","\n","    # Establecer temperatura inicial\n","    temp = initial_temp\n","\n","    # Ciclo principal del algoritmo (iteraciones)\n","    for i in range(n_iterations):\n","\n","        # Crear una solución vecina modificando una sola variable aleatoriamente\n","        neighbor = current.copy()\n","        idx = np.random.randint(n_features)  # escoger una posición aleatoria\n","        neighbor[idx] = 1 - neighbor[idx]    # cambiar de 0→1 o de 1→0\n","\n","        # Evaluar la nueva solución vecina\n","        neighbor_score = evaluate_solution(neighbor)\n","\n","        # Calcular la diferencia en rendimiento (delta)\n","        delta = neighbor_score - current_score\n","\n","        # Criterio de aceptación tipo Metropolis:\n","        # - Si la nueva solución es mejor (delta > 0), se acepta siempre.\n","        # - Si es peor, se acepta con cierta probabilidad que depende de delta y la temperatura.\n","        if delta > 0 or np.exp(delta / temp) > np.random.rand():\n","            current = neighbor\n","            current_score = neighbor_score\n","\n","            # Si además esta nueva solución es la mejor de todas, la guardamos\n","            if current_score > best_score:\n","                best = current.copy()\n","                best_score = current_score\n","\n","        # Reducir la temperatura gradualmente (enfriamiento simulado)\n","        temp *= cooling_rate\n","\n","        # Mostrar información de progreso cada 20 iteraciones y en la última\n","        if i % 20 == 0 or i == n_iterations - 1:\n","            print(f\"Iteración {i}: Precisión = {current_score:.4f}, Temp = {temp:.4f}\")\n","            # print(f\"Iteración {i}: Precisión = {-current_score:.4f}, Temp = {temp:.4f}\")\n","\n","    # Al finalizar, se retorna la mejor solución encontrada\n","    return best, best_score"],"metadata":{"id":"CwcPCvvxwU2e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Resultados"],"metadata":{"id":"9xOkHw_9aWP-"}},{"cell_type":"code","source":["best_sa, score_sa = simulated_annealing()\n","\n","print(f\"\\nMejor precisión SA: {score_sa:.4f}\")\n","# print(f\"\\nMejor precisión SA: {-score_sa:.4f}\")\n","print(f\"Variables seleccionadas: {np.sum(best_sa)}\")\n","\n","# Mostrar nombres de las variables seleccionadas\n","feature_names_array = np.array(data.feature_names)\n","selected_features_sa = feature_names_array[best_sa == 1]\n","for feature in selected_features_sa:\n","    print(f\"- {feature}\")"],"metadata":{"id":"505oRXQraWZN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Algoritmo Genético (Genetic Algorithm, GA)\n","\n","¿Qué hace este algoritmo?\n","* Crea una población inicial de soluciones (máscaras binarias de selección de variables).\n","* Evalúa su desempeño mediante validación cruzada.\n","* Selecciona los mejores individuos para formar la siguiente generación.\n","* Genera nuevos individuos aplicando cruce y mutación.\n","* Itera por varias generaciones, refinando las soluciones.\n","* Devuelve el mejor conjunto de variables al final del proceso.\n","\n"],"metadata":{"id":"a_L4r785lFo9"}},{"cell_type":"code","source":["def genetic_algorithm(pop_size=20, generations=10, crossover_rate=0.8, mutation_rate=0.1):\n","    \"\"\"\n","    Algoritmo genético para seleccionar un subconjunto óptimo de variables que maximice\n","    el rendimiento de un algoritmo de regresión (en este caso, bosques aleatorios).\n","\n","    Parámetros:\n","    - pop_size: número de individuos en la población.\n","    - generations: número total de generaciones que se van a evolucionar.\n","    - crossover_rate: probabilidad de realizar cruce entre padres.\n","    - mutation_rate: probabilidad de mutar un hijo.\n","\n","    Retorna:\n","    - best_ind: el mejor individuo (máscara de variables seleccionadas).\n","    - score: precisión (fitness) de ese individuo.\n","    \"\"\"\n","\n","    # Inicializar población aleatoria\n","    population = [np.random.randint(0, 2, size=n_features) for _ in range(pop_size)]\n","\n","    # Seguimiento del mejor encontrado en TODO el proceso\n","    best_overall = None\n","    best_overall_score = -np.inf\n","\n","    for gen in range(generations):\n","        # 1) Evaluar todos los individuos UNA vez (y almacenar los scores)\n","        scores = np.array([evaluate_solution(ind) for ind in population])\n","\n","        # 2) Actualizar mejor de la generación y mejor global\n","        best_idx_gen = np.argmax(scores)\n","        best_score_gen = scores[best_idx_gen]\n","\n","        if best_score_gen > best_overall_score:\n","            best_overall_score = best_score_gen\n","            best_overall = population[best_idx_gen].copy()\n","\n","        # Mostrar progreso usando el score ya calculado (sin reevaluar)\n","        print(f\"Generación {gen + 1}: Mejor precisión = {best_score_gen:.4f}\")\n","        # print(f\"Generación {gen + 1}: Mejor precisión = {-best_score_gen:.4f}\")\n","\n","        # 3) Selección: tomar los top-k individuos (puedes ajustar k)\n","        k = max(2, pop_size // 2)  # por ejemplo, quedarnos con la mitad superior\n","        top_idx = np.argsort(scores)[-k:]  # índices de los mejores k individuos\n","        selected = [population[i] for i in top_idx]\n","\n","        # 4) Reproducción (cruce + mutación) para crear la nueva población\n","        new_population = []\n","        while len(new_population) < pop_size:\n","            # Seleccionar dos padres aleatoriamente entre los 'selected'\n","            parents = random.sample(selected, 2)\n","\n","            # Cruce por punto\n","            if np.random.rand() < crossover_rate:\n","                point = np.random.randint(1, n_features - 1)\n","                child1 = np.concatenate((parents[0][:point], parents[1][point:]))\n","                child2 = np.concatenate((parents[1][:point], parents[0][point:]))\n","            else:\n","                # Copias si no hay cruce (hacer copia explícita)\n","                child1 = parents[0].copy()\n","                child2 = parents[1].copy()\n","\n","            # Mutación: aquí aplicamos mutación por gen con probabilidad mutation_rate\n","            for child in (child1, child2):\n","                # recorrer genes y mutar con probabilidad mutation_rate\n","                for g in range(n_features):\n","                    if np.random.rand() < mutation_rate:\n","                        child[g] = 1 - child[g]\n","                new_population.append(child)\n","                if len(new_population) >= pop_size:\n","                    break\n","\n","        # Reemplazar población\n","        population = new_population[:pop_size]\n","\n","    # Al final devolver el mejor global y su score (ya guardado)\n","    return best_overall, best_overall_score"],"metadata":{"id":"hU8wNrjTu07x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Resultados"],"metadata":{"id":"1PRHM7esu0Ca"}},{"cell_type":"code","source":["best_ga, score_ga = genetic_algorithm()\n","\n","print(f\"\\nMejor precisión GA: {score_ga:.4f}\")\n","# print(f\"\\nMejor precisión GA: {-score_ga:.4f}\")\n","print(f\"Variables seleccionadas: {np.sum(best_ga)}\")\n","\n","# Mostrar nombres de las variables seleccionadas\n","feature_names_array = np.array(data.feature_names)\n","selected_features_ga = feature_names_array[best_ga == 1]\n","for feature in selected_features_ga:\n","    print(f\"- {feature}\")"],"metadata":{"id":"zageuMVZnOvM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Enjambre de partículas (Particle Swarm Optimization, PSO)\n","\n","* Cada partícula es un vector binario que indica si una característica está incluida (1) o excluida (0).\n","* El fitness (aptitud) es la precisión promedio de un RandomForestRegressor usando solo esas variables.\n","* PSO ajusta las posiciones (máscaras) y velocidades de las partículas para maximizar el fitness.\n"],"metadata":{"id":"qBQ5YWMQnKoN"}},{"cell_type":"code","source":["def binary_pso(n_particles=30, max_iter=10, w=0.7, c1=1.5, c2=1.5):\n","    \"\"\"\n","    Implementación de PSO binario para selección de variables.\n","\n","    Parámetros:\n","    - n_particles: número de partículas\n","    - max_iter: iteraciones máximas\n","    - w: inercia\n","    - c1: factor cognitivo (atracción hacia mejor posición personal)\n","    - c2: factor social (atracción hacia mejor posición global)\n","    \"\"\"\n","    # Inicializar posiciones (0 o 1) y velocidades aleatorias\n","    positions = np.random.randint(0, 2, size=(n_particles, n_features))\n","    velocities = np.random.rand(n_particles, n_features)\n","\n","    # Evaluar fitness inicial\n","    fitness = np.array([evaluate_solution(p) for p in positions])\n","\n","    # Mejor posición personal y global\n","    personal_best_positions = positions.copy()\n","    personal_best_scores = fitness.copy()\n","    global_best_idx = np.argmax(fitness)\n","    global_best_position = positions[global_best_idx].copy()\n","    global_best_score = fitness[global_best_idx]\n","\n","    # Iteraciones principales\n","    for it in range(max_iter):\n","        iteration_scores = []\n","        for i in range(n_particles):\n","            # Actualizar velocidad\n","            r1 = np.random.rand(n_features)\n","            r2 = np.random.rand(n_features)\n","            velocities[i] = (\n","                w * velocities[i] +\n","                c1 * r1 * (personal_best_positions[i] - positions[i]) +\n","                c2 * r2 * (global_best_position - positions[i])\n","            )\n","\n","            # Actualizar posición usando función sigmoide (versión binaria)\n","            sigmoid = 1 / (1 + np.exp(-velocities[i]))\n","            positions[i] = (np.random.rand(n_features) < sigmoid).astype(int)\n","\n","            # Evaluar nueva posición\n","            score = evaluate_solution(positions[i])\n","\n","            # Agregar el score a la lista iteration_scores\n","            iteration_scores.append(score)\n","\n","            # Actualizar mejor personal\n","            if score > personal_best_scores[i]:\n","                personal_best_scores[i] = score\n","                personal_best_positions[i] = positions[i].copy()\n","\n","                # Actualizar mejor global\n","                if score > global_best_score:\n","                    global_best_score = score\n","                    global_best_position = positions[i].copy()\n","\n","        # Mejor precisión encontrada en ESTA iteración\n","        best_iteration_score = max(iteration_scores)\n","        print(f\"Iteración {it+1}/{max_iter} - Mejor precisión: {best_iteration_score:.4f}\")\n","        # print(f\"Iteración {it+1}/{max_iter} - Mejor precisión: {-best_iteration_score:.4f}\")\n","\n","    return global_best_position, global_best_score"],"metadata":{"id":"agJYdwnOnKbP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Resultados"],"metadata":{"id":"uWeRpt-_nQLL"}},{"cell_type":"code","source":["best_mask, best_score = binary_pso()\n","\n","print(f\"\\nMejor precisión PSO: {best_score:.4f}\")\n","# print(f\"\\nMejor precisión PSO: {-best_score:.4f}\")\n","print(\"Variables seleccionadas:\", np.sum(best_mask))\n","\n","feature_names_array = np.array(data.feature_names)\n","for feat in feature_names_array[best_mask == 1]:\n","    print(\"-\", feat)"],"metadata":{"id":"bNdyrL1hnQUO"},"execution_count":null,"outputs":[]}]}