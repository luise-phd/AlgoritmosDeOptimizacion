{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+WjDv71rA1MA7jepxMBAg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Optimización de Hiperparámetros\n","\n","El siguiente ejemplo implementa la solución a problema básico de clasificación usando una red neuronal (MLPClassifier), entrenada con el conjunto de datos digits (dígitos manuscritos), y con optimización bayesiana de hiperparámetros usando Optuna."],"metadata":{"id":"cycrRbLJS2LU"}},{"cell_type":"markdown","source":["### Importar librerías"],"metadata":{"id":"LzgNdY8RT_Sh"}},{"cell_type":"code","source":["import math\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","try:\n","    # Librería de optimización bayesiana para ajuste de hiperparámetros\n","    import optuna\n","    print(\"Librería 'optuna' instalada y cargada correctamente\")\n","    print(optuna.__version__)\n","except:\n","    print(\"Librería 'optuna' no instalada, se procederá con la instalación\")\n","    !pip install scikit-learn optuna\n","    # Librería de optimización bayesiana para ajuste de hiperparámetros\n","    import optuna\n","    print(optuna.__version__)\n","\n","# Conjunto de datos de dígitos manuscritos incluido en scikit-learn\n","from sklearn.datasets import load_digits\n","\n","# Funciones para dividir los datos y realizar validación cruzada\n","from sklearn.model_selection import train_test_split, cross_val_score\n","\n","# Clasificador de perceptrón multicapa (red neuronal)\n","from sklearn.neural_network import MLPClassifier\n","\n","# Normalizador de características (media = 0, varianza = 1)\n","from sklearn.preprocessing import StandardScaler\n","\n","# Pipelines o tuberías (flujo de procesamiento) de pasos de preprocesamiento y modelado\n","# Garantiza que primero se transforman los datos (fit/transform) y luego se entrene o evalúe el modelo final (fit/predict).\n","from sklearn.pipeline import make_pipeline\n","\n","# Métrica para evaluar la precisión del modelo (proporción de aciertos)\n","from sklearn.metrics import accuracy_score\n","\n","# Ignorar las advertencias\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"voUTvseDT-o3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cargar datos y dividirlos en entrenamiento y pruebas"],"metadata":{"id":"2BIL7-tqwAmR"}},{"cell_type":"code","source":["# Carga el conjunto de datos de dígitos manuscritos (8x8 píxeles)\n","digits = load_digits()\n","\n","# Separa las características (X) y las etiquetas (y) del conjunto de datos\n","X, y = digits.data, digits.target\n","\n","# Divide el conjunto de datos en entrenamiento (80%) y prueba (20%)\n","# El parámetro random_state asegura que la división sea reproducible\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"rEJXtz9vwEHv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Descripción del dataset"],"metadata":{"id":"2AI1kmbe1i_-"}},{"cell_type":"code","source":["print(digits.DESCR)"],"metadata":{"id":"UYyFwlYM1brl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Convertir a DataFrame para visualizar el conjunto de datos"],"metadata":{"id":"O-so0JEh1vic"}},{"cell_type":"code","source":["df = pd.DataFrame(digits.data, columns=digits.feature_names)\n","\n","# Agregar la columna de etiquetas\n","df['target'] = digits.target\n","\n","# Mostrar las primeras 5 filas\n","df.head()"],"metadata":{"id":"Y-w2d_4g1vyw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dimensiones del dataset"],"metadata":{"id":"3FiZbzmw2Egn"}},{"cell_type":"code","source":["print(df.shape)\n","print('Cantidad de registros:', df.shape[0])\n","print('Cantidad de variables:', df.shape[1])"],"metadata":{"id":"i-fs6R4G2Eol"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Desplegar la imagen del número ubicado en la fila 0"],"metadata":{"id":"eahLCFU02XMZ"}},{"cell_type":"code","source":["# Extraer el primer ejemplo\n","# reshape convierte el vector de 64 elementos en una matriz de 2 dimensiones 8×8\n","number = X[0].reshape(8, 8)\n","\n","# Graficar la imagen\n","plt.figure(figsize=(2, 2))\n","plt.imshow(number, cmap=plt.cm.gray_r)  # cmap puede ser 'binary', 'gray' o 'gray_r'\n","plt.title(f\"Etiqueta real: {y[0]}\")  # Mostrar la etiqueta del dígito\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"oCOWD79B2XTh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Función objetivo para Optuna"],"metadata":{"id":"M-iL1PgyYQRd"}},{"cell_type":"code","source":["def objective(trial):\n","    # Definición del espacio de búsqueda\n","\n","    # Definir el número y tamaño de las capas ocultas de la red neuronal\n","    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(64,), (100,), (64, 64), (100, 50)])\n","\n","    # Función de activación para las neuronas de la red\n","    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic'])\n","\n","    # Algoritmo de optimización (solver) usado para entrenar la red\n","    solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n","\n","    # Parámetro de regularización L2 (penalización de pesos grandes)\n","    alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n","\n","    # Tasa de aprendizaje inicial para el optimizador\n","    learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n","\n","    # Crear un pipeline (flujo de procesamiento) que incluye estandarización de datos\n","    # y un clasificador MLP (red neuronal multicapa)\n","    clf = make_pipeline(\n","\n","        # Paso 1: Estandarizar los datos con media=0 y desviación estándar=1.\n","        # Esto es importante porque las redes neuronales son sensibles a la escala de las variables\n","        StandardScaler(),\n","\n","        # Paso 2: Entrenar un clasificador MLP (red neuronal multicapa) con los hiperparámetros seleccionados\n","        MLPClassifier(\n","            hidden_layer_sizes=hidden_layer_sizes,   # Arquitectura de la red (número de neuronas en cada capa oculta).\n","            activation=activation,                   # Función de activación ('relu', 'tanh' o 'logistic').\n","            solver=solver,                           # Algoritmo de optimización ('adam' o 'sgd').\n","            alpha=alpha,                             # Parámetro de regularización L2 para evitar sobreajuste.\n","            learning_rate_init=learning_rate_init,   # Tasa de aprendizaje inicial.\n","            max_iter=100,                            # Número máximo de iteraciones (épocas) de entrenamiento.\n","            random_state=42                          # Semilla para reproducibilidad de resultados.\n","        )\n","    )\n","\n","    # Validación cruzada\n","    score = cross_val_score(clf, X_train, y_train, cv=3, scoring='accuracy')\n","\n","    return score.mean()"],"metadata":{"id":"DXygDEmmX_nw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejecutar la optimización"],"metadata":{"id":"7gkNrGbdYvEa"}},{"cell_type":"code","source":["%%time\n","\n","# Crear un estudio de Optuna para optimización de hiperparámetros.\n","# direction='maximize' → indica que queremos maximizar la métrica objetivo\n","# (ejemplo: accuracy, AUC, F1). Si quisiéramos minimizar (ej. RMSE, error),\n","# se usaría direction='minimize'.\n","study = optuna.create_study(direction='maximize')\n","\n","# Ejecutar la optimización del estudio.\n","#   - objective   → función que entrena y evalúa el modelo, devolviendo la métrica que se desea optimizar.\n","#   - n_trials=10 → número de experimentos (combinaciones de hiperparámetros) que Optuna va a probar.\n","study.optimize(objective, n_trials=10)\n","\n","# Mostrar mejores hiperparámetros\n","print(\"\\nMejores hiperparámetros encontrados:\")\n","print(study.best_params)"],"metadata":{"id":"GmMZgUZxYvNS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluar el mejor modelo en el conjunto de prueba"],"metadata":{"id":"0ioIUR2Wva0w"}},{"cell_type":"code","source":["%%time\n","\n","# Obtener los mejores hiperparámetros encontrados por Optuna\n","best_params = study.best_params\n","\n","# Crear un pipeline con dos pasos:\n","# 1. Estandarización de datos (StandardScaler)\n","# 2. Red neuronal multicapa (MLPClassifier) con los mejores hiperparámetros\n","best_model = make_pipeline(\n","    StandardScaler(),   # Escalar los datos (media=0, varianza=1) antes de entrenar\n","\n","    MLPClassifier(\n","        hidden_layer_sizes=best_params['hidden_layer_sizes'],   # Arquitectura óptima (número y tamaño de capas ocultas)\n","        activation=best_params['activation'],                   # Función de activación óptima (relu, tanh o logistic)\n","        solver=best_params['solver'],                           # Algoritmo de optimización óptimo (adam o sgd)\n","        alpha=best_params['alpha'],                             # Regularización L2 óptima (para evitar sobreajuste)\n","        learning_rate_init=best_params['learning_rate_init'],   # Tasa de aprendizaje inicial óptima\n","        max_iter=100,                                           # Número máximo de iteraciones (épocas) de entrenamiento\n","        random_state=42                                         # Semilla para reproducibilidad\n","    )\n",")\n","\n","# Entrenar el modelo con los datos de entrenamiento\n","best_model.fit(X_train, y_train)\n","\n","# Predecir las etiquetas en el conjunto de prueba\n","y_pred = best_model.predict(X_test)\n","\n","# Calcular la precisión comparando predicciones con valores reales\n","acc = accuracy_score(y_test, y_pred)\n","\n","# Mostrar la precisión en el conjunto de prueba con 4 decimales\n","print(f\"Precisión en el conjunto de prueba: {acc:.4f}\")"],"metadata":{"id":"_WHp06WIvZL0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Resumen de la evaluación"],"metadata":{"id":"ODnuyHp69QES"}},{"cell_type":"code","source":["# Imprimir el número total de elementos en el conjunto de prueba\n","print(\"Elementos de prueba: {}\".format(y_test.shape[0]))\n","\n","# Contar cuántas predicciones fueron incorrectas (comparando y_test vs y_pred)\n","print(\"Errores identificados: {}\".format((y_test != y_pred).sum()))\n","\n","# Calcular el porcentaje de error:\n","#   - Número de errores dividido entre total de elementos de prueba\n","#   - Multiplicado por 100 para expresarlo en porcentaje\n","porcentaje_error = ((y_test != y_pred).sum() * 100) / y_test.shape[0]\n","\n","# Mostrar el porcentaje de error con formato de texto\n","print(\"Porcentaje de error: {} %\".format(porcentaje_error))"],"metadata":{"id":"7WIUJblE8qV_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Errores en las predicciones del conjunto de datos de prueba"],"metadata":{"id":"RoAEq3yB9W4v"}},{"cell_type":"code","source":["# Seleccionar las muestras del conjunto de prueba en las que el modelo se equivocó.\n","errores = X_test[y_test != y_pred]\n","\n","# Extraer las etiquetas reales correspondientes a esas muestras mal clasificadas\n","real_labels = y_test[y_test != y_pred]\n","print(\"Etiquetas reales    :\", real_labels)\n","\n","# Extraer las etiquetas que el modelo predijo para esas mismas muestras\n","predicted_labels = y_pred[y_test != y_pred]\n","print(\"Etiquetas estimadas :\", predicted_labels)\n","\n","# Imprimir cuántos errores cometió el modelo en el conjunto de prueba\n","print(\"Cantidad de errores:\", len(errores))"],"metadata":{"id":"cxHvyskv83qZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Graficar las primeras 5 filas de errores"],"metadata":{"id":"kFfdjjtm9i29"}},{"cell_type":"code","source":["k = 0   # Contador para limitar cuántos bloques de imágenes mostrar\n","\n","# Recorrer los errores en bloques de 5 muestras cada uno\n","# math.ceil() permite \"redondear hacia arriba\" (ceil = techo), ademas\n","# garantiza que no se pierda ningún error aunque el número total no sea múltiplo exacto de 5\n","for j in range(math.ceil(errores.shape[0] / 5)):\n","\n","    # Crear una figura de 10x10 pulgadas para cada bloque\n","    plt.figure(figsize=(10,10))\n","\n","    # Sub-bucle para mostrar 5 imágenes por fila\n","    for i in range(5):\n","\n","        idx = 5*j + i\n","        if idx >= errores.shape[0]:   # Evitar pasarse si no hay más errores\n","            break\n","\n","        # Definir la posición del subplot (1 fila, 5 columnas, posición i+1)\n","        plt.subplot(1, 5, i + 1)\n","\n","        # Eliminar marcas en los ejes x e y\n","        plt.xticks([])\n","        plt.yticks([])\n","\n","        # Quitar la cuadrícula\n","        plt.grid(False)\n","\n","        # Recuperar la imagen del error correspondiente (vector plano de 64 → 8x8)\n","        number = errores[5*j + i].reshape(8, 8)\n","\n","        # Mostrar la imagen en blanco y negro (binary = blanco/negro invertido)\n","        plt.imshow(number, cmap=plt.cm.binary)\n","\n","        # Etiquetar con la clase real y la predicción del modelo\n","        # El bucle externo (for j in range(...)) avanza en bloques de 5 errores cada vez.\n","        # El bucle interno (for i in range(5)) recorre los 5 elementos dentro de ese bloque.\n","        # Entonces, el índice total dentro del arreglo de errores no es solo i ni solo j, sino una combinación de ambos:\n","        #   índice total=(nuˊmero_de_bloque × tamaño_del_bloque) + índice_dentro_del_bloque\n","        plt.xlabel(\"Real: {} Predicción: {}\".format(real_labels[5*j+i], predicted_labels[5*j+i]))\n","\n","    # Mostrar la figura completa con las 5 imágenes\n","    plt.show()\n","\n","    # Aumentar el contador de bloques\n","    k += 1\n","\n","    # Romper el bucle si ya se mostraron 5 bloques (máximo 25 imágenes)\n","    if k == 5:\n","        break"],"metadata":{"id":"79NO9yF98y4E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ¿Qué hace este ejemplo?\n","\n","* Usa el conjunto digits (1797 imágenes de dígitos manuscritos).\n","* Crea un MLPClassifier con diferentes combinaciones de hiperparámetros (capas ocultas, activación, alpha, tasa de aprendizaje...).\n","* Usa Optuna para optimizar esos hiperparámetros mediante validación cruzada.\n","* Evalúa el modelo final con los mejores parámetros sobre el conjunto de prueba."],"metadata":{"id":"kw45YUYnYkb4"}}]}