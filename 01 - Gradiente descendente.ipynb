{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjDgROPOCSXsZr6E3CfVGL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Gradiente Descendente Cl치sico o por Lotes (Batch Gradient Descent)\n","Es un m칠todo de optimizaci칩n que sirve para encontrar el m칤nimo de una funci칩n. Se basa en calcular la derivada (o gradiente) de la funci칩n y moverse en la direcci칩n contraria para ir \"bajando\" por la curva, como si buscaras el punto m치s bajo de un valle."],"metadata":{"id":"kVemp8n_IqDJ"}},{"cell_type":"markdown","source":["### Importar librer칤as"],"metadata":{"id":"iuPgbelzv8mQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wmmKu8TFInvL"},"outputs":[],"source":["# Aunque esta librer칤a no se usa realmente en este ejemplo, es com칰n tenerla para operaciones num칠ricas\n","import numpy as np"]},{"cell_type":"markdown","source":["La funci칩n que queremos minimizar es $f(x) = x^2$. Sabemos que su valor m칤nimo est치 en $洧논=0$, donde $洧녭(洧논)=0$."],"metadata":{"id":"SaWjurBSKJkD"}},{"cell_type":"code","source":["# Funci칩n de p칠rdida (a minimizar): f(x) = x^2\n","def f(x):\n","  return x ** 2"],"metadata":{"id":"6gUjLDdZKLzb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esta es la derivada de la funci칩n anterior, que indica en qu칠 direcci칩n crece la funci칩n."],"metadata":{"id":"NyBDnJ4zKEDV"}},{"cell_type":"code","source":["# Derivada de f(x): f'(x) = 2x\n","def grad_f(x):\n","    return 2 * x"],"metadata":{"id":"R7fjke0jKGx8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Par치metros del algoritmo"],"metadata":{"id":"5U6Nb_uIKPr0"}},{"cell_type":"code","source":["x = 5.0               # Valor inicial\n","learning_rate = 0.1   # Tama침o del paso (qu칠 tan grande es cada paso hacia el m칤nimo)\n","iterations = 10       # N칰mero de iteraciones (cu치ntas veces se aplica el algoritmo)"],"metadata":{"id":"feYOrcNzKQA8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bucle de gradiente descendente\n","* En cada iteraci칩n, se calcula la pendiente de la funci칩n en el punto actual (grad).\n","* Luego se actualiza $x$ restando un paso en direcci칩n contraria al gradiente.\n","* Se imprime el valor actualizado de $x$ y de la funci칩n $f(x)$."],"metadata":{"id":"vcYJxvBeKddq"}},{"cell_type":"code","source":["for i in range(iterations):\n","    grad = grad_f(x)                        # Calcula el gradiente en x\n","    x = x - learning_rate * grad            # Actualiza x movi칠ndose en sentido contrario al gradiente\n","    print(f\"Iteraci칩n {i+1}: x = {x:.4f}, f(x) = {f(x):.4f}\")"],"metadata":{"id":"oPp_GmGsKcfI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dado que $洧녭(洧논)=洧논^2$, el m칤nimo est치 en $洧논=0$. Si comienzas en $洧논=5$, con cada iteraci칩n deber칤as acercarte m치s al cero ($0$)."],"metadata":{"id":"BNiM_zuSLTTi"}}]}