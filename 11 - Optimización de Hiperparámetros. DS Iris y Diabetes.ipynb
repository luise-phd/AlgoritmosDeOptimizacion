{"cells":[{"cell_type":"markdown","id":"e655295b","metadata":{"id":"e655295b"},"source":["## Optimización de Hiperparámetros\n","\n","<p style='text-align: justify'>El autoajuste u optimización de hiperparámetros, también conocido como búsqueda de hiperparámetros, se refiere al proceso de encontrar la mejor combinación de configuraciones para un modelo de aprendizaje automático. Los hiperparámetros son configuraciones ajustables que no se aprenden directamente del conjunto de datos, como la profundidad de un árbol de decisión, la tasa de aprendizaje en una red neuronal o la regularización en un modelo de regresión.</p>\n","\n","<p style='text-align: justify'>El objetivo es optimizar estas configuraciones para mejorar el rendimiento del modelo en términos de una métrica específica, como Accuracy, F1-Score, R<sup>2</sup>, entre otros. Este proceso implica probar diferentes combinaciones de hiperparámetros y evaluar el rendimiento del modelo utilizando validación cruzada u otros métodos de evaluación para determinar cuáles configuraciones proporcionan el mejor rendimiento.</p>\n","\n","<p style='text-align: justify'>Se utilizan técnicas como la búsqueda aleatoria, búsqueda en cuadrícula (grid search), optimización bayesiana, entre otros, para explorar el espacio de hiperparámetros y encontrar la combinación óptima que maximice el rendimiento del modelo en el conjunto de datos. El autoajuste de hiperparámetros es crucial para mejorar la capacidad de generalización y el rendimiento predictivo del modelo.</p>\n","\n","https://scikit-learn.org/stable/modules/grid_search.html\n","\n","https://optuna.org"]},{"cell_type":"markdown","id":"fc573f81","metadata":{"id":"fc573f81"},"source":["#### Otras ténicas para la Optimización de Hiperparámetros\n","1. <b>Optimización Bayesiana</b>: Utiliza métodos bayesianos para encontrar la combinación óptima de hiperparámetros al seleccionar de manera iterativa las configuraciones más prometedoras para evaluar. Métodos como Gaussian Process-based Optimization (GPO) o Tree-structured Parzen Estimator (TPE) son populares en esta área.\n","\n","2. <b>Optimización Evolutiva</b>: Se inspira en conceptos evolutivos y utiliza algoritmos genéticos, estrategias de evolución diferencial u otros métodos similares para buscar eficientemente en el espacio de hiperparámetros en busca de la mejor configuración.\n","\n","3. <b>Optimización basada en gradiente</b>: En lugar de explorar aleatoriamente o mediante una búsqueda sistemática, utiliza la información del gradiente de una métrica de evaluación para ajustar los hiperparámetros de manera iterativa, siguiendo una dirección que maximice o minimice esta métrica.\n","\n","4. <b>Optimización de Hyperband</b>: Esta técnica combina la exploración aleatoria con la eliminación temprana de configuraciones ineficaces. Se ejecutan múltiples configuraciones de forma aleatoria, pero se descartan rápidamente aquellas que no ofrecen buenos resultados, lo que permite enfocarse en las configuraciones prometedoras.\n","\n","Cada una de estas técnicas tiene sus propias ventajas y desventajas, y la elección de la técnica de búsqueda de hiperparámetros depende del conjunto de datos, el tiempo de cómputo disponible y las características del problema que se esté abordando."]},{"cell_type":"markdown","id":"6093cde7","metadata":{"id":"6093cde7"},"source":["### Importar librerías"]},{"cell_type":"code","execution_count":null,"id":"13eb3bbb","metadata":{"id":"13eb3bbb"},"outputs":[],"source":["import pandas as pd\n","\n","# Cargar los conjuntos de datos desde sklearn\n","from sklearn.datasets import load_iris, load_diabetes\n","\n","# Dividir datos y realizar búsquedas de hiperparámetros\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n","\n","# Clasificador RandomForestClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Algoritmo de regresión Support Vector Regressor\n","from sklearn.svm import SVR\n","\n","# Funciones de distribución aleatoria de scipy.stats\n","# randint: genera números enteros aleatorios dentro de un rango (distribución uniforme discreta).\n","# uniform: genera números aleatorios con distribución uniforme continua.\n","from scipy.stats import randint, uniform\n","\n","# Ignorar las advertencias\n","# import warnings\n","# warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"1b49bb82","metadata":{"id":"1b49bb82"},"source":["### Modelo de clasificación usando Random Forest"]},{"cell_type":"markdown","source":["<p style='text-align: justify'>Random Forest (Bosque Aleatorio) es un algoritmo de aprendizaje automático que se utiliza para tareas de clasificación y regresión. Se basa en la construcción de múltiples árboles de decisión y combina sus resultados para mejorar la precisión y la robustez de las predicciones.</p>\n","\n","<p style='text-align: justify'>La idea central detrás es crear un conjunto de árboles de decisión en lugar de depender de un solo árbol. Cada árbol se construye utilizando una muestra aleatoria de los datos de entrenamiento y utilizando una técnica llamada \"bagging\". En este proceso:</p>\n","\n","* Se toma una muestra aleatoria (con reemplazo) de los datos de entrenamiento.\n","* Se construye un árbol de decisión utilizando la muestra seleccionada.\n","* Se repiten los pasos 1 y 2 para construir múltiples árboles.\n","\n","<p style='text-align: justify'>Luego, cuando se hace una predicción, cada árbol en el conjunto emite su propia predicción y la predicción final se determina por votación (en el caso de clasificación) o promedio (en el caso de regresión) de las predicciones de todos los árboles.</p>\n","\n","Las ventajas de Random Forest incluyen:\n","\n","* <b>Reducción del sobreajuste (overfitting)</b>: El ensamblaje de múltiples árboles reduce el riesgo de sobreajuste en comparación con un solo árbol.\n","* <b>Mayor estabilidad</b>: Los errores en la predicción de un solo árbol pueden ser compensados por otros árboles en el conjunto.\n","* Capacidad para manejar conjuntos de datos grandes y dimensiones altas.\n","* Buena capacidad de manejar características categóricas y numéricas sin mucho preprocesamiento.\n","\n","<p style='text-align: justify'>Random Forest se utiliza ampliamente en aplicaciones del mundo real, como clasificación de imágenes, detección de fraudes, análisis de mercado y más. Es una técnica versátil y efectiva para mejorar la precisión y la generalización de los modelos de aprendizaje automático.</p>"],"metadata":{"id":"jXI_EBEnbSFE"},"id":"jXI_EBEnbSFE"},{"cell_type":"markdown","id":"aa3bcd87","metadata":{"id":"aa3bcd87"},"source":["<p style='text-align: justify'>En este ejemplo se muestra  cómo realizar la búsqueda de hiperparámetros utilizando la búsqueda aleatoria (RandomizedSearchCV) y la búsqueda en cuadrícula (GridSearchCV) con un clasificador de Bosques Aleatorios (RandomForestClassifier).</p>"]},{"cell_type":"code","execution_count":null,"id":"85f2c583","metadata":{"id":"85f2c583"},"outputs":[],"source":["# Cargamos un conjunto de datos de ejemplo (Iris)\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Dividimos los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"a50fc02f","metadata":{"id":"a50fc02f"},"source":["#### Conjunto de datos Iris\n","<p style='text-align: justify'>Es un conjunto clásico y comúnmente utilizado en la comunidad de Machine Learning. Fue introducido por el biólogo y estadístico británico Ronald Fisher en 1936. Contiene información sobre tres especies de iris: Setosa, Versicolor y Virginica.</p>\n","\n","<p style='text-align: justify'>Consta de 150 muestras, donde cada especie de iris se representa con 50 muestras. Cada muestra tiene cuatro características: longitud y ancho del sépalo, y longitud y ancho del pétalo, todas en centímetros. Estas características se utilizan para predecir la especie de iris.</p>\n","\n","<p style='text-align: justify'>Se utiliza en problemas de clasificación, ya que es pequeño, fácil de entender y tiene características numéricas bien definidas para predecir la especie de flor de iris basándose en sus características morfológicas.</p>"]},{"cell_type":"code","execution_count":null,"id":"e09b1ef1","metadata":{"id":"e09b1ef1"},"outputs":[],"source":["print(iris.DESCR)"]},{"cell_type":"markdown","source":["### Convertir a DataFrame para visualizar el conjunto de datos"],"metadata":{"id":"I4zUKklgZm10"},"id":"I4zUKklgZm10"},{"cell_type":"code","source":["df = pd.DataFrame(iris.data, columns=iris.feature_names)\n","\n","# Agregar la columna de etiquetas\n","df['target'] = iris.target\n","\n","# Mostrar las primeras 5 filas\n","df.head()"],"metadata":{"id":"XvEYowmyZoHG"},"id":"XvEYowmyZoHG","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dimensiones del dataset"],"metadata":{"id":"KpefLoEnaLc2"},"id":"KpefLoEnaLc2"},{"cell_type":"code","source":["print(df.shape)\n","print('Cantidad de registros:', df.shape[0])\n","print('Cantidad de variables:', df.shape[1])"],"metadata":{"id":"QTeiuAFUaMhB"},"id":"QTeiuAFUaMhB","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"bbd16f85","metadata":{"id":"bbd16f85"},"source":["### Búsqueda aleatoria o Randomized Search\n","<p style='text-align: justify'>Es una técnica de optimización en la que se exploran diferentes combinaciones de hiperparámetros seleccionadas aleatoriamente dentro de un rango definido. En contraste con la Búsqueda en Cuadrícula (Grid Search), que evalúa todas las combinaciones posibles dentro de un conjunto predefinido de valores, la Búsqueda Aleatoria selecciona muestras aleatorias de un espacio de búsqueda.</p>\n","\n","<p style='text-align: justify'>Esta estrategia es útil cuando el espacio de búsqueda de hiperparámetros es grande y no es factible evaluar todas las combinaciones posibles. En lugar de examinar exhaustivamente todas las combinaciones, la Búsqueda Aleatoria selecciona de manera aleatoria un número determinado de configuraciones de hiperparámetros para evaluar. Esta técnica puede resultar más eficiente en tiempo y recursos, especialmente en conjuntos de datos grandes o con modelos complejos.</p>\n","\n","<p style='text-align: justify'>Al probar combinaciones aleatorias de hiperparámetros, la Búsqueda Aleatoria permite explorar el espacio de búsqueda de manera más rápida y, en muchos casos, puede encontrar combinaciones que conduzcan a buenos resultados sin necesidad de probar todas las opciones.</p>"]},{"cell_type":"code","execution_count":null,"id":"fc4bf3a6","metadata":{"id":"fc4bf3a6"},"outputs":[],"source":["%%time\n","\n","# Definir los hiperparámetros para la búsqueda aleatoria\n","param_dist = {\n","    'n_estimators': randint(100, 150), # Número de árboles en el bosque aleatorio\n","    'max_depth': randint(3, 10), # Profundidad máxima de cada árbol en el bosque\n","    'min_samples_split': randint(2, 10), # Número mínimo de muestras requeridas para dividir un nodo interno\n","    'min_samples_leaf': randint(1, 5), # Número mínimo de muestras necesarias para que un nodo sea considerado hoja\n","    'bootstrap': [True, False] # Parámetro booleano que indica si se debe usar o no, el muestreo con reemplazo\n","}\n","\n","# Clasificador de Bosques Aleatorios\n","rf = RandomForestClassifier()\n","\n","# Búsqueda aleatoria\n","random_search = RandomizedSearchCV(\n","    rf,                    # Modelo a optimizar.\n","    param_distributions=param_dist,  # Diccionario con los hiperparámetros y sus posibles valores.\n","    n_iter=15,             # Número de combinaciones aleatorias de hiperparámetros a probar.\n","    cv=5,                  # Validación cruzada con 5 particiones (para evaluar la calidad de cada combinación).\n","    # scoring=\"f1_weighted\", # Definición de la métrica: F1 Score → \"f1\" (para binario) o \"f1_macro\", \"f1_micro\", \"f1_weighted\" (para multiclase).\n","    random_state=42        # Semilla para reproducibilidad de los resultados (los mismos aleatorios en cada ejecución).\n",")\n","\n","# Entrenamiento del modelo y búsqueda de los mejores hiperparámetros.\n","random_search.fit(X_train, y_train)"]},{"cell_type":"markdown","id":"04d55470","metadata":{"id":"04d55470"},"source":["### Evaluación del modelo"]},{"cell_type":"code","execution_count":null,"id":"5b496135","metadata":{"id":"5b496135"},"outputs":[],"source":["# Muestra los mejores hiperparámetros encontrados por la búsqueda aleatoria\n","print(\"Mejores hiperparámetros de Random Search:\\n{}\\n\".format(random_search.best_params_))\n","\n","# Evalua los modelos en el conjunto de prueba\n","random_search_score = random_search.score(X_test, y_test)\n","\n","print(\"Precisión (accuracy) en el conjunto de prueba:\", random_search_score)\n","# print(\"Presición (F1 Score) en el conjunto de prueba:\", random_search_score)"]},{"cell_type":"markdown","id":"9acf9fb5","metadata":{"id":"9acf9fb5"},"source":["### Búsqueda en cuadrícula o Grid Search\n","<p style='text-align: justify'>Es una técnica de optimización que evalúa exhaustivamente un conjunto predefinido de combinaciones de hiperparámetros para determinar la configuración óptima que maximiza el rendimiento del modelo.</p>\n","\n","<p style='text-align: justify'>En esta estrategia, se define un conjunto de valores posibles para cada hiperparámetro que se desea ajustar y se genera un \"grid\" o cuadrícula con todas las posibles combinaciones de estos valores. Luego, se entrena y evalúa el modelo utilizando cada combinación de hiperparámetros dentro de esta cuadrícula, y se selecciona aquella configuración que ofrezca el mejor rendimiento de acuerdo con una métrica de evaluación específica, como precisión, F1-score, AUC, entre otras.</p>\n","\n","<p style='text-align: justify'>Aunque la Búsqueda en Cuadrícula es exhaustiva y garantiza evaluar todas las combinaciones posibles dentro del espacio definido, puede resultar costosa computacionalmente en comparación con otras técnicas, especialmente cuando el espacio de búsqueda es grande o cuando se tienen conjuntos de datos extensos. Sin embargo, proporciona una manera sistemática de encontrar la mejor combinación de hiperparámetros para un modelo.</p>"]},{"cell_type":"code","execution_count":null,"id":"e588acf0","metadata":{"id":"e588acf0"},"outputs":[],"source":["%%time\n","\n","param_grid = {\n","    'n_estimators': [100, 110, 120],\n","    'max_depth': [3, 5, 7],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2],\n","    'bootstrap': [True, False]\n","}\n","\n","grid_search = GridSearchCV(\n","    rf,\n","    param_grid=param_grid,\n","    cv=5,\n","    # scoring=\"f1_macro\",\n",")\n","\n","grid_search.fit(X_train, y_train)"]},{"cell_type":"markdown","id":"0983e491","metadata":{"id":"0983e491"},"source":["### Evaluación del modelo"]},{"cell_type":"code","execution_count":null,"id":"e250e617","metadata":{"id":"e250e617"},"outputs":[],"source":["print(\"Mejores hiperparámetros de Grid Search:\\n{}\\n\".format(grid_search.best_params_))\n","grid_search_score = grid_search.score(X_test, y_test)\n","print(\"Precisión (accuracy) en el conjunto de prueba:\", random_search_score)\n","# print(\"Presición (F1 Score) en el conjunto de prueba:\", random_search_score)"]},{"cell_type":"markdown","id":"5c4136b8","metadata":{"id":"5c4136b8"},"source":["<p style='text-align: justify'>En ambos tipos de búsqueda, ya sea con RandomizedSearchCV o GridSearchCV, la métrica predeterminada que se utiliza para evaluar la calidad del modelo en cada combinación de hiperparámetros es la precisión (accuracy) en el caso de problemas de clasificación.</p>\n","\n","<p style='text-align: justify'>La precisión es una métrica comúnmente utilizada en problemas de clasificación y representa la proporción de predicciones correctas realizadas por el modelo sobre el total de predicciones realizadas.</p>"]},{"cell_type":"markdown","id":"f1d4ac45","metadata":{"id":"f1d4ac45"},"source":["### Conclusión\n","<p style='text-align: justify'>El conjunto de datos Iris es conocido por ser un conjunto de datos relativamente pequeño y limpio, con clases bien separadas, lo que puede resultar en una alta precisión para varios algoritmos de clasificación. En el ejemplo se obtuvo una precisión de 1.0 (o 100%) durante la búsqueda de hiperparámetros, eso es justificable debido a la naturaleza de este conjunto de datos.</p>\n","\n","<p style='text-align: justify'>Consta de tres clases de plantas que son distinguibles mediante características específicas como longitud y ancho del sépalo y pétalo. Dado que estas clases son altamente separables y los modelos de clasificación pueden aprender fácilmente a distinguirlas, es posible lograr una alta precisión, especialmente con algoritmos como Random Forest, que tienden a funcionar bien en conjuntos de datos pequeños y limpios.</p>\n","\n","<p style='text-align: justify'>Por lo tanto, en el contexto del conjunto de datos Iris, es posible obtener resultados de precisión altos sin que necesariamente indiquen sobreajuste o errores en el modelo.</p>"]},{"cell_type":"markdown","id":"56b63bd3","metadata":{"id":"56b63bd3"},"source":["### Modelo de regresión usando Support Vector Regressor (SVR)\n","\n","<p style='text-align: justify'>SVR es una técnica de regresión que se basa en el concepto de Máquinas de soporte vectorial (SVM) empleado en problemas de clasificación.</p>\n","\n","<p style='text-align: justify'>SVR busca encontrar una función de regresión en un espacio de alta dimensión, donde los puntos de datos, representados como vectores, están separados por un margen con el objetivo de minimizar el error de predicción. Funciona encontrando el hiperplano que maximiza el margen alrededor de los puntos de datos más cercanos, denominados vectores de soporte. A diferencia de la regresión lineal, SVR puede manejar relaciones no lineales mediante el uso de funciones de kernel, permitiendo la transformación de los datos a un espacio de mayor dimensión donde los datos puedan ser linealmente separables.</p>\n","\n","<p style='text-align: justify'>El objetivo principal de SVR es minimizar la cantidad de errores, permitiendo cierto grado de error tolerable. SVR intenta ajustar una función que se ajuste a la mayoría de los puntos de datos dentro del margen tolerable, al mismo tiempo que minimiza las desviaciones de los puntos de datos más cercanos. Esto lo logra mediante la optimización de una función de costo que equilibra la precisión del modelo y la amplitud del margen, controlada por parámetros como C (parámetro de regularización) y la elección del kernel.</p>"]},{"cell_type":"code","execution_count":null,"id":"ed0fe8f7","metadata":{"id":"ed0fe8f7"},"outputs":[],"source":["# Cargar el conjunto de datos\n","diabetes = load_diabetes()\n","X, y = diabetes.data, diabetes.target\n","\n","# Dividir el conjunto de datos en entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"9d445b04","metadata":{"id":"9d445b04"},"source":["#### Conjunto de datos diabetes\n","<p style='text-align: justify'>El conjunto de datos diabetes es un conjunto de datos clásico que contiene información médica relevante para el estudio de la diabetes. Este conjunto de datos incluye diez variables fisiológicas (edad, sexo, índice de masa corporal, presión arterial y seis mediciones de suero sanguíneo) y una medida cuantitativa de la progresión de la enfermedad un año después del inicio del estudio.</p>\n","\n","<p style='text-align: justify'>Las variables son todos valores continuos y representan características médicas relevantes, mientras que el objetivo es una medida cuantitativa de la progresión de la enfermedad.</p>\n","\n","<p style='text-align: justify'>Este conjunto de datos se utiliza comúnmente para tareas de regresión donde el objetivo es predecir la progresión de la enfermedad basándose en las características médicas proporcionadas.</p>"]},{"cell_type":"code","execution_count":null,"id":"4334142e","metadata":{"id":"4334142e"},"outputs":[],"source":["print(diabetes.DESCR)"]},{"cell_type":"markdown","id":"d56d6090","metadata":{"id":"d56d6090"},"source":["### Búsqueda aleatoria"]},{"cell_type":"code","execution_count":null,"id":"33090377","metadata":{"id":"33090377"},"outputs":[],"source":["%%time\n","\n","# Definir los hiperparámetros para la búsqueda aleatoria\n","param_dist = {\n","    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], # Tipos de kernel que definen la función de transformación de datos.\n","    'C': uniform(loc=0, scale=100),                 # Parámetro de regularización (controla la penalización de errores). Se muestrea entre 0 y 100\n","    'gamma': ['scale', 'auto'],                     # Parámetro que controla la influencia de cada punto de entrenamiento en kernels no lineales\n","    'epsilon': uniform(loc=0, scale=1)              # Margen de tolerancia para el error en SVR. Se muestrea de una distribución uniforme entre 0 y 1\n","}\n","\n","# Crear el modelo de regresión\n","svr = SVR()\n","\n","# Búsqueda aleatoria\n","random_search = RandomizedSearchCV(\n","    svr,\n","    param_distributions=param_dist,\n","    n_iter=100,\n","    cv=5,\n","    # scoring=\"neg_mean_squared_error\",   # MSE (negativo)\n","    random_state=42\n",")\n","\n","# Entrenamiento del modelo y búsqueda de los mejores hiperparámetros.\n","random_search.fit(X_train, y_train)"]},{"cell_type":"markdown","id":"d27a6466","metadata":{"id":"d27a6466"},"source":["### Evaluación del modelo"]},{"cell_type":"code","execution_count":null,"id":"88579a47","metadata":{"id":"88579a47"},"outputs":[],"source":["# Mejores hiperparámetros encontrados mediante búsqueda aleatoria\n","print(\"\\nMejores hiperparámetros encontrados mediante búsqueda aleatoria:\")\n","print(random_search.best_params_)\n","\n","# R² en entrenamiento y prueba con los mejores hiperparámetros\n","print(\"\\nR² en entrenamiento:\", random_search.score(X_train, y_train))\n","print(\"R² en prueba:\", random_search.score(X_test, y_test))\n","\n","# MSE en entrenamiento y prueba con los mejores hiperparámetros\n","# print(\"\\nMSE en entrenamiento:\", -random_search.score(X_train, y_train))\n","# print(\"MSE en prueba:\", -random_search.score(X_test, y_test))"]},{"cell_type":"markdown","id":"39d5c239","metadata":{"id":"39d5c239"},"source":["### Búsqueda en cuadrícula"]},{"cell_type":"code","execution_count":null,"id":"cf335cff","metadata":{"id":"cf335cff"},"outputs":[],"source":["%%time\n","\n","# Búsqueda en cuadrícula alrededor de los mejores hiperparámetros encontrados\n","param_grid = {\n","    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': ['scale', 'auto'],\n","    'epsilon': list(uniform(loc=0, scale=1).rvs(10)) # rvs(n) (Random Variates Sample) genera n muestras aleatorias de esa distribución.\n","                                                     # En este caso: 10 valores aleatorios uniformes en el rango [0,1].\n","}\n","\n","# Búsqueda en cuadrícula\n","grid_search = GridSearchCV(\n","    svr,\n","    param_grid=param_grid,\n","    cv=5,\n","    # scoring=\"neg_mean_squared_error\"   # MSE (negativo)\n",")\n","\n","grid_search.fit(X_train, y_train)"]},{"cell_type":"markdown","id":"6f6ddcd7","metadata":{"id":"6f6ddcd7"},"source":["### Evaluación del modelo"]},{"cell_type":"code","execution_count":null,"id":"cca07d4e","metadata":{"id":"cca07d4e"},"outputs":[],"source":["# Mejores hiperparámetros encontrados mediante búsqueda en cuadrícula\n","print(\"\\nMejores hiperparámetros encontrados mediante búsqueda en cuadrícula:\")\n","print(grid_search.best_params_)\n","\n","# R² en entrenamiento y prueba con los mejores hiperparámetros\n","print(\"\\nR² en entrenamiento:\", grid_search.score(X_train, y_train))\n","print(\"R² en prueba:\", grid_search.score(X_test, y_test))\n","\n","# MSE en entrenamiento y prueba con los mejores hiperparámetros\n","# print(\"\\nMSE en entrenamiento:\", -grid_search.score(X_train, y_train))\n","# print(\"MSE en prueba:\", -grid_search.score(X_test, y_test))"]},{"cell_type":"markdown","id":"980212f6","metadata":{"id":"980212f6"},"source":["#### Conclusión\n","<p style='text-align: justify'>El coeficiente de determinación (R²) es una medida que indica la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes en un modelo de regresión. Un valor R² cercano a 1 indica un buen ajuste del modelo a los datos, donde el modelo explica una gran parte de la variabilidad de la variable dependiente. Un valor cercano a 0.5 sugiere que el modelo está capturando una parte significativa, pero no toda, de la variabilidad de los datos.</p>\n","\n","<p style='text-align: justify'>En el caso específico de SVR (Support Vector Regression), el R² alrededor de 0.5 puede significar que el modelo está capturando parte de la variabilidad en el conjunto de datos diabetes. Sin embargo, es importante tener en cuenta que diferentes conjuntos de datos pueden mostrar diferentes niveles de predictibilidad debido a su naturaleza.</p>\n","\n","<p style='text-align: justify'>Un R² de 0.5 también podría indicar que el modelo no puede explicar completamente la variabilidad de la variable dependiente con las características proporcionadas, lo que puede ser común en conjuntos de datos complejos o en problemas donde hay múltiples factores influyentes que no están siendo considerados por el modelo. En algunos casos, un R-cuadrado de 0.5 puede considerarse aceptable dependiendo del contexto del problema y las expectativas del rendimiento del modelo.</p>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}